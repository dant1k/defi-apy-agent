#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –∏–∫–æ–Ω–æ–∫
"""

import os
import hashlib
from pathlib import Path
from collections import defaultdict

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏
ICONS_DIR = Path("frontend/public/icons")
BACKUP_DIR = Path("api/static/icons")

def get_file_hash(file_path: Path) -> str:
    """–ü–æ–ª—É—á–∏—Ç—å MD5 —Ö–µ—à —Ñ–∞–π–ª–∞"""
    try:
        with open(file_path, 'rb') as f:
            return hashlib.md5(f.read()).hexdigest()
    except:
        return ""

def get_file_size(file_path: Path) -> int:
    """–ü–æ–ª—É—á–∏—Ç—å —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞ –≤ –±–∞–π—Ç–∞—Ö"""
    try:
        return file_path.stat().st_size
    except:
        return 0

def find_duplicates_in_directory(directory: Path, category: str):
    """–ù–∞–π—Ç–∏ –¥—É–±–ª–∏–∫–∞—Ç—ã –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏"""
    print(f"\nüîç Checking {category} for duplicates...")
    
    if not directory.exists():
        print(f"  ‚Üí Directory {directory} does not exist")
        return
    
    # –°–æ–±–∏—Ä–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ñ–∞–π–ª–∞—Ö
    file_info = {}
    hash_to_files = defaultdict(list)
    
    for file_path in directory.glob("*.png"):
        file_hash = get_file_hash(file_path)
        file_size = get_file_size(file_path)
        
        if file_hash:
            file_info[file_path.name] = {
                'path': file_path,
                'hash': file_hash,
                'size': file_size
            }
            hash_to_files[file_hash].append(file_path.name)
    
    # –ò—â–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã
    duplicates = []
    for file_hash, files in hash_to_files.items():
        if len(files) > 1:
            duplicates.append({
                'hash': file_hash,
                'files': files,
                'size': file_info[files[0]]['size']
            })
    
    if duplicates:
        print(f"  ‚ùå Found {len(duplicates)} duplicate groups:")
        total_wasted_space = 0
        
        for i, dup in enumerate(duplicates, 1):
            wasted_space = dup['size'] * (len(dup['files']) - 1)
            total_wasted_space += wasted_space
            
            print(f"    {i}. Hash: {dup['hash'][:8]}...")
            print(f"       Size: {dup['size']} bytes")
            print(f"       Files: {', '.join(dup['files'])}")
            print(f"       Wasted space: {wasted_space} bytes")
            print()
        
        print(f"  üìä Total wasted space: {total_wasted_space} bytes ({total_wasted_space/1024:.1f} KB)")
    else:
        print(f"  ‚úÖ No duplicates found in {category}")
    
    return duplicates

def find_duplicates_between_directories():
    """–ù–∞–π—Ç–∏ –¥—É–±–ª–∏–∫–∞—Ç—ã –º–µ–∂–¥—É –ª–æ–∫–∞–ª—å–Ω—ã–º–∏ –∏ backup –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è–º–∏"""
    print(f"\nüîç Checking for duplicates between local and backup directories...")
    
    # –°–æ–±–∏—Ä–∞–µ–º —Ö–µ—à–∏ –∏–∑ –ª–æ–∫–∞–ª—å–Ω—ã—Ö –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π
    local_hashes = {}
    for category in ['chains', 'tokens', 'protocols']:
        local_dir = ICONS_DIR / category
        if local_dir.exists():
            for file_path in local_dir.glob("*.png"):
                file_hash = get_file_hash(file_path)
                if file_hash:
                    local_hashes[file_hash] = {
                        'path': file_path,
                        'category': category,
                        'name': file_path.name
                    }
    
    # –°–æ–±–∏—Ä–∞–µ–º —Ö–µ—à–∏ –∏–∑ backup –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π
    backup_hashes = {}
    for category in ['chains', 'tokens', 'protocols']:
        backup_dir = BACKUP_DIR / category
        if backup_dir.exists():
            for file_path in backup_dir.glob("*.png"):
                file_hash = get_file_hash(file_path)
                if file_hash:
                    backup_hashes[file_hash] = {
                        'path': file_path,
                        'category': category,
                        'name': file_path.name
                    }
    
    # –ò—â–µ–º –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏—è
    cross_duplicates = []
    for file_hash in local_hashes:
        if file_hash in backup_hashes:
            local_info = local_hashes[file_hash]
            backup_info = backup_hashes[file_hash]
            
            cross_duplicates.append({
                'hash': file_hash,
                'local': local_info,
                'backup': backup_info
            })
    
    if cross_duplicates:
        print(f"  ‚ùå Found {len(cross_duplicates)} cross-duplicates:")
        total_wasted_space = 0
        
        for i, dup in enumerate(cross_duplicates, 1):
            local_size = get_file_size(dup['local']['path'])
            total_wasted_space += local_size
            
            print(f"    {i}. Hash: {dup['hash'][:8]}...")
            print(f"       Local: {dup['local']['category']}/{dup['local']['name']}")
            print(f"       Backup: {dup['backup']['category']}/{dup['backup']['name']}")
            print(f"       Size: {local_size} bytes")
            print()
        
        print(f"  üìä Total wasted space: {total_wasted_space} bytes ({total_wasted_space/1024:.1f} KB)")
    else:
        print(f"  ‚úÖ No cross-duplicates found")
    
    return cross_duplicates

def get_directory_stats():
    """–ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è–º"""
    print(f"\nüìä Directory Statistics:")
    
    total_files = 0
    total_size = 0
    
    for category in ['chains', 'tokens', 'protocols']:
        local_dir = ICONS_DIR / category
        backup_dir = BACKUP_DIR / category
        
        local_files = 0
        local_size = 0
        if local_dir.exists():
            for file_path in local_dir.glob("*.png"):
                local_files += 1
                local_size += get_file_size(file_path)
        
        backup_files = 0
        backup_size = 0
        if backup_dir.exists():
            for file_path in backup_dir.glob("*.png"):
                backup_files += 1
                backup_size += get_file_size(file_path)
        
        total_files += local_files + backup_files
        total_size += local_size + backup_size
        
        print(f"  {category.capitalize()}:")
        print(f"    Local: {local_files} files, {local_size/1024:.1f} KB")
        print(f"    Backup: {backup_files} files, {backup_size/1024:.1f} KB")
        print(f"    Total: {local_files + backup_files} files, {(local_size + backup_size)/1024:.1f} KB")
        print()
    
    print(f"  üìä Grand Total: {total_files} files, {total_size/1024:.1f} KB ({total_size/1024/1024:.1f} MB)")

def main():
    print("üîç Checking for duplicate icons...")
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π
    get_directory_stats()
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã –≤–Ω—É—Ç—Ä–∏ –∫–∞–∂–¥–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
    all_duplicates = []
    
    for category in ['chains', 'tokens', 'protocols']:
        # –õ–æ–∫–∞–ª—å–Ω—ã–µ –¥—É–±–ª–∏–∫–∞—Ç—ã
        local_dir = ICONS_DIR / category
        local_dups = find_duplicates_in_directory(local_dir, f"Local {category}")
        if local_dups:
            all_duplicates.extend(local_dups)
        
        # Backup –¥—É–±–ª–∏–∫–∞—Ç—ã
        backup_dir = BACKUP_DIR / category
        backup_dups = find_duplicates_in_directory(backup_dir, f"Backup {category}")
        if backup_dups:
            all_duplicates.extend(backup_dups)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã –º–µ–∂–¥—É –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è–º–∏
    cross_dups = find_duplicates_between_directories()
    
    # –ò—Ç–æ–≥–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    print(f"\nüìä Duplicate Summary:")
    print(f"  Internal duplicates: {len(all_duplicates)} groups")
    print(f"  Cross-directory duplicates: {len(cross_dups)} files")
    
    if all_duplicates or cross_dups:
        print(f"\nüí° Recommendation: Consider removing duplicates to save space")
    else:
        print(f"\n‚úÖ No duplicates found! Great optimization!")

if __name__ == "__main__":
    main()

